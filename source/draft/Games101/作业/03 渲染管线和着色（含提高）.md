---
tags: ["作业","Games101","图形学"]
date: 2023-09-27
title: 03 渲染管线和着色（含提高） 
password: 211511011
message: 此文章转载请与作者处观看https://www.yuque.com/gaoshanliushui-mbfny
---
# 分析
在前两次作业的基础上，添加光照模型和材质处理。
因为对我来说难度还是有点大，做了一天。参考了论坛和博客，我会把它们放在最后。
值得注意的是，作业框架和上课内容部分有出入，但问题不大。
其中bump和displacement部分基本按照注释写的，并不能完全理解，论坛说有些超纲了。
# 渲染管线
## 输入处理
输入处理主要集中在`main.cpp->main`函数中

首先记录每个小三角形的顶点信息，小三角形为光栅化的单位。

```cpp
// 文件目录
    std::string filename = "output.png";
    objl::Loader Loader;
    std::string obj_path = "../models/spot/";

    // 加载.obj文件
    bool loadout = Loader.LoadFile("../models/spot/spot_triangulated_good.obj");
    // 遍历模型的每个面
    for(auto mesh:Loader.LoadedMeshes)
    {
        // 记录图形每个面中连续三个顶点（小三角形）
        for(int i=0;i<mesh.Vertices.size();i+=3)
        {
            Triangle* t = new Triangle();
            // 把每个小三角形的顶点信息记录在Triangle类t中
            for(int j=0;j<3;j++)
            {
                t->setVertex(j,Vector4f(mesh.Vertices[i+j].Position.X,mesh.Vertices[i+j].Position.Y,mesh.Vertices[i+j].Position.Z,1.0));// 记录顶点位置
                t->setNormal(j,Vector3f(mesh.Vertices[i+j].Normal.X,mesh.Vertices[i+j].Normal.Y,mesh.Vertices[i+j].Normal.Z));// 记录顶点法线
                t->setTexCoord(j,Vector2f(mesh.Vertices[i+j].TextureCoordinate.X, mesh.Vertices[i+j].TextureCoordinate.Y));// 记录顶点纹理
            }
            TriangleList.push_back(t);// 三角形信息加入列表
        }
    }
```

然后构造光栅化对象，把输入参数的光栅化shader传入光栅化调用的function对象中。

```cpp
  rst::rasterizer r(700, 700);// 构造光栅化对象

    // 记录纹理到光栅化
    auto texture_path = "hmap.jpg";
    r.set_texture(Texture(obj_path + texture_path));

    std::function<Eigen::Vector3f(fragment_shader_payload)> active_shader = phong_fragment_shader;// 定义shader的function对象

    // 输入处理 用参数设置shader的function对象或设置纹理
    if (argc >= 2)
    {
        command_line = true;
        filename = std::string(argv[1]);

        if (argc == 3 && std::string(argv[2]) == "texture")
        {
            std::cout << "Rasterizing using the texture shader\n";
            active_shader = texture_fragment_shader;
            texture_path = "spot_texture.png";
            r.set_texture(Texture(obj_path + texture_path));
        }
        else if (argc == 3 && std::string(argv[2]) == "normal")
        {
            std::cout << "Rasterizing using the normal shader\n";
            active_shader = normal_fragment_shader;
        }
        else if (argc == 3 && std::string(argv[2]) == "phong")
        {
            std::cout << "Rasterizing using the phong shader\n";
            active_shader = phong_fragment_shader;
        }
        else if (argc == 3 && std::string(argv[2]) == "bump")
        {
            std::cout << "Rasterizing using the bump shader\n";
            active_shader = bump_fragment_shader;
        }
        else if (argc == 3 && std::string(argv[2]) == "displacement")
        {
            std::cout << "Rasterizing using the displacement shader\n";
            active_shader = displacement_fragment_shader;
        }
    }
```

之后算出MVP变换矩阵并通过draw函数正式进入渲染管线流程。

```cpp
    r.set_vertex_shader(vertex_shader);// 设置顶点着色方式
    r.set_fragment_shader(active_shader);// 设置片元着色方式

    int key = 0;
    int frame_count = 0;

    if (command_line)
    {
        r.clear(rst::Buffers::Color | rst::Buffers::Depth);// 清空缓冲区
        // 分别得到MVP变换矩阵
        r.set_model(get_model_matrix(angle));
        r.set_view(get_view_matrix(eye_pos));
        r.set_projection(get_projection_matrix(45.0, 1, 0.1, 50));

		// 应用变换矩阵 并进行光栅化、片元处理、帧缓冲
        r.draw(TriangleList);


        return 0;
    }
```
## 顶点、三角形处理阶段
```cpp
void rst::rasterizer::draw(std::vector<Triangle*>& TriangleList) {

	float f1 = (50 - 0.1) / 2.0;// zfar和znear距离的一半
	float f2 = (50 + 0.1) / 2.0;// zfar和znear的中心z坐标

	Eigen::Matrix4f mvp = projection * view * model;// 计算MVP变换矩阵
	// 遍历每个小三角形
	for (const auto& t : TriangleList)
	{
		Triangle newtri = *t;

		// 计算viewspace_pos，其中viewspace_pos的坐标是经过MV变换，没有经过P投影变换
		// 所以默认在相机坐标系而不是世界坐标系

		// 记录三角形顶点MV变换后坐标
		std::array<Eigen::Vector4f, 3> mm{
				(view * model * t->v[0]),
				(view * model * t->v[1]),
				(view * model * t->v[2])
		};

		std::array<Eigen::Vector3f, 3> viewspace_pos;

		// 存入viewspace_pos
		std::transform(mm.begin(), mm.end(), viewspace_pos.begin(), [](/auto& v) {
			return v.template head<3>();
			});

		// 得到经过mvp后的坐标
		Eigen::Vector4f v[] = {
				mvp * t->v[0],
				mvp * t->v[1],
				mvp * t->v[2]
		};

		// 换算齐次坐标
		for (auto& vec : v) {
			vec.x() /= vec.w();
			vec.y() /= vec.w();
			vec.z() /= vec.w();
		}

		// 计算在MV转换后各顶点的法向量
		// 利用原来点法向量推出MV变换后法向量
		// 因为光线作用是在view_space下进行的
		Eigen::Matrix4f inv_trans = (view * model).inverse().transpose();
		Eigen::Vector4f n[] = {
				inv_trans * to_vec4(t->normal[0], 0.0f),
				inv_trans * to_vec4(t->normal[1], 0.0f),
				inv_trans * to_vec4(t->normal[2], 0.0f)
		};

		// 视口变换 得到顶点在屏幕上的坐标 即screen space
		for (auto& vert : v)
		{
			vert.x() = 0.5 * width * (vert.x() + 1.0);
			vert.y() = 0.5 * height * (vert.y() + 1.0);
			// 为了Zbuffer保留Z值
			// （透视）投影变换最后一步是从正交投影变换到正则立方体
			// 而这一步就是把正则立方体的z值还原到正交投影时的z值，即原始z值
			vert.z() = vert.z() * f1 + f2;
		}

		// 记录经过MVP视口变换后的顶点坐标
		// 完成顶点变换，变换到屏幕空间
		for (int i = 0; i < 3; ++i)
		{
			//screen space coordinates
			newtri.setVertex(i, v[i]);
		}

		// 记录顶点的法向量
		for (int i = 0; i < 3; ++i)
		{
			//view space normal
			newtri.setNormal(i, n[i].head<3>());
		}

		// 设置颜色
		newtri.setColor(0, 148, 121.0, 92.0);
		newtri.setColor(1, 148, 121.0, 92.0);
		newtri.setColor(2, 148, 121.0, 92.0);

		// 对这个小三角形进行光栅化
		// 传入viewspace_pos的坐标，光线的作用是在viewspace下的
		rasterize_triangle(newtri, viewspace_pos);
	}
}
```

- 顶点进行MV操作，得到viewspace中的坐标`viewspace_pos`，这个坐标用于后续的光线作用。光线作用发生在视图空间。
- 顶点进行MVP+视口操作，把三维空间顶点坐标换算到二维空间即screen space上。 
   - 在其次变换中，w并未发生变换，它记录了原本的z值信息，用于后续的插值。
   - 视口变换中，将(x, y)变换到二维平面，而z值变为原始z值，用于后续Z-buffer算法。透视投影变换=变换到正交投影+变换到正则立方体，即把z值逆变换回正交投影时的z值。
- 记录viewspace下的顶点法向量。因为光线作用在viewspace下。

光线作用发生在view space：
![](/images/posts/1694861783443-41dbf52b-b504-4646-932a-2e0f8a4cc80b.png)
![](/images/posts/1694861783500-42aaa284-7cf5-4079-804b-d738ed432747.png)

视口变换：

```cpp
// 视口变换 得到顶点在屏幕上的坐标 即screen space
for (auto& vert : v)
{
	vert.x() = 0.5 * width * (vert.x() + 1.0);
	vert.y() = 0.5 * height * (vert.y() + 1.0);
	// 为了Zbuffer保留Z值
	// （透视）投影变换最后一步是从正交投影变换到正则立方体
	// 而这一步就是把正则立方体的z值还原到正交投影时的z值，即原始z值
	vert.z() = vert.z() * f1 + f2;
}
```

笔记中视口变换的定义是先不考虑z轴，把MVP后处于标准立方体$[-1,1]^{3}$映射到屏幕上。
首先我们知道视口变换矩阵：

$M_{viewport}=
\begin{bmatrix}
\frac{width}{2}& 0& 0& \frac{width}{2}\\ 
0& \frac{height}{2}& 0& \frac{height}{2}\\
0& 0& 1& 0\\ 
0& 0& 0& 1
\end{bmatrix}$

根据行操作展开可以得到$(x, y)^{T}$的值。
Z值实际上是要进行保留的，用于之后的Z-buffer算法。
具体来说，透视投影即P变换分为两步：透视投影变正交投影+正交投影变正则立方体。
而Z值要还原的地方就是正角立方体变为正则立方体前的值。
我们知道

$M_{ortho}=\begin{bmatrix}\frac{2}{r-l}& 0& 0& -\frac{r+l}{r-l}\\ 0& \frac{2}{t-b}& 0& -\frac{t+b}{t-b}\\ 0& 0& \frac{2}{n-f}& -\frac{n+f}{n-f}\\ 0& 0& 0& 1\end{bmatrix}$

令还原的值为z，经过MVP变换还未经过视口变换的现在的值为z'。

$$\begin{aligned}
z'&=\frac{2}{n-f}z-\frac{n+f}{n-f}\\
z&=\frac{n-f}{2}z'+\frac{n+f}{2}
\end{aligned}$$

viewspace下的顶点法向量：

```cpp
// 计算在MV转换后各顶点的法向量
// 利用原来点法向量推出MV变换后法向量
// 因为光线作用是在view_space下进行的
Eigen::Matrix4f inv_trans = (view * model).inverse().transpose();
Eigen::Vector4f n[] = {
		inv_trans * to_vec4(t->normal[0], 0.0f),
		inv_trans * to_vec4(t->normal[1], 0.0f),
		inv_trans * to_vec4(t->normal[2], 0.0f)
};
```

已知：MV变换前法向量$\vec{n}$，切线$\vec{t}$。设经过MV操作后法向量变为$\vec{n'}$，切线为$vec{t'}$，MV变换矩阵为$\mathbf{A}=\mathbf{M_{view}}\times \mathbf{M_{modle}}$。
则有：
$$\begin{aligned}
\vec{n}^{T}\times \vec{t} &= 0\\
\vec{n'}^{T}\times (\mathbf{A}\vec{t}) &= 0
\end{aligned}$$ 
password: 211511011
message: 此文章转载请与作者处观看https://www.yuque.com/gaoshanliushui-mbfny
---------------------------------帮助------------------------------------
这里关于为什么 :
$$\begin{aligned}
\vec{n}^{T}\times \vec{t} &= 0\\
\end{aligned}$$
可以观看:	

- [https://zhuanlan.zhihu.com/p/359975221](/https://zhuanlan.zhihu.com/p/359975221)
- ![](/images/posts/1694926830365-674d41e9-5887-467d-a4b4-60f248607781.jpeg.jpg)
 
password: 211511011
message: 此文章转载请与作者处观看https://www.yuque.com/gaoshanliushui-mbfny
--------------------------------------------------------------------------
令两式相等，两边同时乘以$\vec{t}^{-1}\mathbf{A^{-1}}$：

$$\begin{aligned}
\vec{n'}^{T}&=\vec{n}^{T}\times \mathbf{A^{-1}}\\
\vec{n'}&=(\mathbf{A^{-1}})^{T}\times \vec{n}
\end{aligned}$$
## 光栅化、片元处理、帧缓冲阶段
```cpp
void rst::rasterizer::rasterize_triangle(const Triangle& t, const std::array<Eigen::Vector3f, 3>& view_pos)
{
	auto v = t.toVector4();
	// Bouding Box
	int min_x = std::min(v[0].x(), std::min(v[1].x(), v[2].x())), min_y = std::min(v[0].y(), std::min(v[1].y(), v[2].y())), max_x = std::max(v[0].x(), std::max(v[1].x(), v[2].x())), max_y = std::max(v[0].y(), std::max(v[1].y(), v[2].y()));

	// 采样
	for (int x = min_x; x <= max_x; x++)
		for (int y = min_y; y <= max_y; y++)
		{
			if (insideTriangle(x + 0.5, y + 0.5, t.v))
			{
				// Z-Buffer算法
				// 获取当前像素的深度
				// 线性插值，透视矫正
					//    * v[i].w() is the vertex view space depth value z.
					//    * Z is interpolated view space depth for the current pixel
					//    * zp is depth between zNear and zFar, used for z-buffer
				auto tmp = computeBarycentric2D(x + 0.5, y + 0.5, t.v);
				float alpha, beta, gamma;
				std::tie(alpha, beta, gamma) = tmp;
				float Z = 1.0 / (alpha / v[0].w() + beta / v[1].w() + gamma / v[2].w());
				float zp = alpha * v[0].z() / v[0].w() + beta * v[1].z() / v[1].w() + gamma * v[2].z() / v[2].w();
				zp *= Z;
				if (zp < depth_buf[get_index(x, y)])// 当前深度更靠前
				{
					depth_buf[get_index(x, y)] = zp;
					auto interpolated_color = interpolate(alpha, beta, gamma, t.color[0], t.color[1], t.color[2], 1);
					auto interpolated_normal = interpolate(alpha, beta, gamma, t.normal[0], t.normal[1], t.normal[2], 1).normalized();
					auto interpolated_texcoords = interpolate(alpha, beta, gamma, t.tex_coords[0], t.tex_coords[1], t.tex_coords[2], 1);
					// 前面提到 光照作用是在视图坐标下的
					auto interpolated_shadingcoords = interpolate(alpha, beta, gamma, view_pos[0], view_pos[1], view_pos[2], 1);

					// 把信息存到shader参数中
					fragment_shader_payload payload(interpolated_color, interpolated_normal.normalized(), interpolated_texcoords, texture ? &*texture : nullptr);
					payload.view_pos = interpolated_shadingcoords;
					auto pixel_color = fragment_shader(payload);

					set_pixel(Vector2i(x, y), pixel_color);
				}
			}
		}
}
```

光栅化阶段：

- bouding box
- 采样，判断每个像素是否在小三角形内，如果在，进行深度测试——深度插值得到这个像素的z值与缓存进行比较。
- 通过深度测试后对三角形各个属性进行插值计算。

片元处理阶段：

- 把三角形插值信息传入shader参数中并调用片元处理函数

帧缓冲阶段：

- 把shader处理结果传到frame_buffer中(set_pixel)

重心坐标：
求中心坐标函数`computerBarycentric2D`：

```cpp
static std::tuple<float, float, float> computeBarycentric2D(float x, float y, const Vector4f* v) {
	float c1 = (x * (v[1].y() - v[2].y()) + (v[2].x() - v[1].x()) * y + v[1].x() * v[2].y() - v[2].x() * v[1].y()) / (v[0].x() * (v[1].y() - v[2].y()) + (v[2].x() - v[1].x()) * v[0].y() + v[1].x() * v[2].y() - v[2].x() * v[1].y());
	float c2 = (x * (v[2].y() - v[0].y()) + (v[0].x() - v[2].x()) * y + v[2].x() * v[0].y() - v[0].x() * v[2].y()) / (v[1].x() * (v[2].y() - v[0].y()) + (v[0].x() - v[2].x()) * v[1].y() + v[2].x() * v[0].y() - v[0].x() * v[2].y());
	float c3 = (x * (v[0].y() - v[1].y()) + (v[1].x() - v[0].x()) * y + v[0].x() * v[1].y() - v[1].x() * v[0].y()) / (v[2].x() * (v[0].y() - v[1].y()) + (v[1].x() - v[0].x()) * v[2].y() + v[0].x() * v[1].y() - v[1].x() * v[0].y());
	return { c1,c2,c3 };
}
```

对应重心坐标公式：
![](/images/posts/1694861783432-65eef2ef-c70b-468b-8db2-e12bfb4689f3.png)

深度插值（这部分来自[https://blog.csdn.net/Q_pril/article/details/123598746）：](/https://blog.csdn.net/Q_pril/article/details/123598746%EF%BC%89%EF%BC%9A)
[https://www.yuque.com/ancientelement/zz9t0b/kvgw4gc4beg42558#1ccc9e61](/https://www.yuque.com/ancientelement/zz9t0b/kvgw4gc4beg42558#1ccc9e61)

- 重点是 二维重心坐标 与 三维重心坐标 之间存在误差我们需要修正误差
- 前提条件 : $z_1' = z_1,z_2' = z_2,z_3' = z_3$且 是 顶点是同一点
![](/images/posts/1694861783511-774492cc-d953-485f-929f-6ee9dc9689eb.png)
![](/images/posts/1694861783542-8ff907c8-a1f2-4303-902a-70bceef3a054.png)
![](/images/posts/1694861784249-bc4f039b-cfb6-4665-a601-34c8d0be4db1.png)
![](/images/posts/1694861784424-3c89546b-1d24-4e79-8d1e-5fe3c086fcdb.png)
![](/images/posts/1694861784396-866cd992-a2a1-4253-a828-e8ee4d10acd1.png)

属性插值：
![](/images/posts/1694861784887-56097c45-b730-4dc6-913a-146203413854.png)
原论坛：[https://games-cn.org/forums/topic/zuoye3-guanyushenduzhiwentizijicaidekengheyixiexiangfa/](/https://games-cn.org/forums/topic/zuoye3-guanyushenduzhiwentizijicaidekengheyixiexiangfa/)
## 显示
`main.cpp->main()`

```cpp
cv::Mat image(700, 700, CV_32FC3, r.frame_buffer().data());
image.convertTo(image, CV_8UC3, 1.0f);
cv::cvtColor(image, image, cv::COLOR_RGB2BGR);

cv::imwrite(filename, image);
```

利用opencv自带的方法从frame_buffer中取出计算好的数据画在图中并存储。
# 着色模型
## normal模型

```cpp
// 根据法线进行不同着色
Eigen::Vector3f normal_fragment_shader(const fragment_shader_payload& payload)
{
    Eigen::Vector3f return_color = (payload.normal.head<3>().normalized() + Eigen::Vector3f(1.0f, 1.0f, 1.0f)) / 2.f;
    Eigen::Vector3f result;
    result << return_color.x() * 255, return_color.y() * 255, return_color.z() * 255;
    return result;
}
```

这个函数并不是光照模型，只是根据不同法线返回不同颜色值。
第一行的代码，首先取出当前待着色像素点的法向量的X,Y,Z坐标并归一化，故此时X,Y,Z都在[-1,1]之间，加上（1.0f, 1.0f, 1.0f）后，变为[0,2]，再除以2，即得[0,1]，再分别乘以255即可得到各个颜色值了。

normal模型渲染结果：
![](/images/posts/1694861784635-3162cae7-20ef-4bad-9e67-23862b55c788.png)
## phong模型
```cpp
Eigen::Vector3f phong_fragment_shader(const fragment_shader_payload& payload)
{
    // 泛光、漫反射、高光系数
    Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
    Eigen::Vector3f kd = payload.color;
    Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

    // 灯光位置和强度
    auto l1 = light{{20, 20, 20}, {500, 500, 500}};
    auto l2 = light{{-20, 20, 0}, {500, 500, 500}};

    std::vector<light> lights = {l1, l2};// 光照
    Eigen::Vector3f amb_light_intensity{10, 10, 10};// 环境光强度
    Eigen::Vector3f eye_pos{0, 0, 10};// 相机位置

    float p = 150;

    // ping point的信息
    Eigen::Vector3f color = payload.color;
    Eigen::Vector3f point = payload.view_pos;// view space
    Eigen::Vector3f normal = payload.normal;

    Eigen::Vector3f result_color = {0, 0, 0};// 光照结果

    Eigen::Vector3f La = ka.cwiseProduct(amb_light_intensity);
    // 遍历每一束光
    for (auto& light : lights)
    {
        Eigen::Vector3f l = (light.position - point).normalized(), v = (eye_pos - point).normalized();// 光照方向和观察方向
        Eigen::Vector3f h = (l + v).normalized();// 半程向量
        Eigen::Vector3f I = light.intensity;// 光强
        float r2 = (light.position - point).dot(light.position - point);
        Eigen::Vector3f Ld = kd.cwiseProduct(I / r2) * std::max(0.0f, normal.dot(l));//cwiseProduct()函数允许Matrix直接进行点对点乘法,而不用转换至Array
        Eigen::Vector3f Ls = ks.cwiseProduct(I / r2) * std::pow(std::max(0.0f, normal.dot(h)), p);
        result_color += La + Ld + Ls;
    }
    //Eigen::Vector3f La = ka.cwiseProduct(amb_light_intensity);
    //result_color += La;
    return result_color * 255.f;
}
```

直接根据公式写就行，这里我认为环境光应该放在循环外，不过这样渲出来的结果相比说说明偏暗，但后面的displacement又要放在外面否则偏亮。

phong模型渲染结果：
![](/images/posts/1694861785135-802864bc-4bdc-44e3-8fdb-1799169f4513.png)
## texture模型
```cpp
Eigen::Vector3f texture_fragment_shader(const fragment_shader_payload& payload)
{
    Eigen::Vector3f return_color = {0, 0, 0};
    if (payload.texture)
    {
        return_color = payload.texture->getColor(payload.tex_coords.x(), payload.tex_coords.y());// 获取材质颜色信息
    }
    Eigen::Vector3f texture_color;
    texture_color << return_color.x(), return_color.y(), return_color.z();

    Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
    Eigen::Vector3f kd = texture_color / 255.f;// 材质颜色影响漫反射系数
    Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

    auto l1 = light{{20, 20, 20}, {500, 500, 500}};
    auto l2 = light{{-20, 20, 0}, {500, 500, 500}};

    std::vector<light> lights = {l1, l2};
    Eigen::Vector3f amb_light_intensity{10, 10, 10};
    Eigen::Vector3f eye_pos{0, 0, 10};

    float p = 150;

    Eigen::Vector3f color = texture_color;
    Eigen::Vector3f point = payload.view_pos;
    Eigen::Vector3f normal = payload.normal;

    Eigen::Vector3f result_color = {0, 0, 0};

    Eigen::Vector3f La = ka.cwiseProduct(amb_light_intensity);
    for (auto& light : lights)
    {
        Eigen::Vector3f l = (light.position - point).normalized(), v = (eye_pos - point).normalized();// 光照方向和观察方向
        Eigen::Vector3f h = (l + v).normalized();// 半程向量
        Eigen::Vector3f I = light.intensity;// 光强
        float r2 = (light.position - point).dot(light.position - point);
        Eigen::Vector3f Ld = kd.cwiseProduct(I / r2) * std::max(0.0f, normal.dot(l));//cwiseProduct()函数允许Matrix直接进行点对点乘法,而不用转换至Array
        Eigen::Vector3f Ls = ks.cwiseProduct(I / r2) * std::pow(std::max(0.0f, normal.dot(h)), p);
        result_color += La + Ld + Ls;
    }
    // Eigen::Vector3f La = ka.cwiseProduct(amb_light_intensity);
    // result_color += La;
    return result_color * 255.f;
}
```

只需要理解纹理影响颜色，颜色影响漫反射系数。所以在一开始读取材质纹理的颜色信息，再传给漫反射系数，之后再套用phong模型即可。

这里框架有一个问题，就是在`getColor`中，没有限制UV坐标的范围，加上即可。

```cpp
Eigen::Vector3f getColor(float u, float v)
{
	// 限制(u, v)坐标范围
	u = std::fmin(1, std::fmax(u, 0));
	v = std::fmin(1, std::fmax(v, 0));

	auto u_img = u * width;
	auto v_img = (1 - v) * height;
	auto color = image_data.at<cv::Vec3b>(v_img, u_img);// 四舍五入
	return Eigen::Vector3f(color[0], color[1], color[2]);
}
```

这样做后，控制台(vs2019)会显示一个报错，不过并不影响结果。

texture模型渲染结果：
![](/images/posts/1694861785353-3627675c-b435-4365-9359-61b3c2c96612.png)
## bump和displacement模型
这一部分助教在论坛说会在光线追踪部分详细介绍，现在按照注释实现即可。
所以原理我目前也不是完全明白...

```cpp

Eigen::Vector3f bump_fragment_shader(const fragment_shader_payload& payload)
{

    Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
    Eigen::Vector3f kd = payload.color;
    Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

    auto l1 = light{ {20, 20, 20}, {500, 500, 500} };
    auto l2 = light{ {-20, 20, 0}, {500, 500, 500} };

    std::vector<light> lights = { l1, l2 };
    Eigen::Vector3f amb_light_intensity{ 10, 10, 10 };
    Eigen::Vector3f eye_pos{ 0, 0, 10 };

    float p = 150;

    Eigen::Vector3f color = payload.color;
    Eigen::Vector3f point = payload.view_pos;
    Eigen::Vector3f normal = payload.normal;


    float kh = 0.2, kn = 0.1;

    // TODO: Implement bump mapping here
    // Let n = normal = (x, y, z)
    // Vector t = (x*y/sqrt(x*x+z*z),sqrt(x*x+z*z),z*y/sqrt(x*x+z*z))
    // Vector b = n cross product t
    // Matrix TBN = [t b n]

    float x = normal.x();
    float y = normal.y();
    float z = normal.z();
    Eigen::Vector3f t{ x * y / std::sqrt(x * x + z * z), std::sqrt(x * x + z * z), z * y / std::sqrt(x * x + z * z) };
    Eigen::Vector3f b = normal.cross(t);
    Eigen::Matrix3f TBN;
    TBN << t.x(), b.x(), normal.x(),
        t.y(), b.y(), normal.y(),
        t.z(), b.z(), normal.z();

    // dU = kh * kn * (h(u+1/w,v)-h(u,v))
    // dV = kh * kn * (h(u,v+1/h)-h(u,v))
    // Vector ln = (-dU, -dV, 1)
    // Normal n = normalize(TBN * ln)

    float u = payload.tex_coords.x(), v = payload.tex_coords.y();
    float w = payload.texture->width, h = payload.texture->height;

    float dU = kh * kn * (payload.texture->getColor(u + 1.0f / w, v).norm() - payload.texture->getColor(u, v).norm());
    float dV = kh * kn * (payload.texture->getColor(u, v + 1.0f / h).norm() - payload.texture->getColor(u, v).norm());

    Eigen::Vector3f ln{ -dU,-dV,1.0f };

    normal = TBN * ln;
    // 归一化
    Eigen::Vector3f result_color = normal.normalized();
    return result_color * 255.f;
}
```

bump模型渲染结果：
![](/images/posts/1694861785440-16a5ec18-7b13-47ee-8b36-1385b173a6f0.png)

```cpp

Eigen::Vector3f displacement_fragment_shader(const fragment_shader_payload& payload)
{

    Eigen::Vector3f ka = Eigen::Vector3f(0.005, 0.005, 0.005);
    Eigen::Vector3f kd = payload.color;
    Eigen::Vector3f ks = Eigen::Vector3f(0.7937, 0.7937, 0.7937);

    auto l1 = light{ {20, 20, 20}, {500, 500, 500} };
    auto l2 = light{ {-20, 20, 0}, {500, 500, 500} };

    std::vector<light> lights = { l1, l2 };
    Eigen::Vector3f amb_light_intensity{ 10, 10, 10 };
    Eigen::Vector3f eye_pos{ 0, 0, 10 };

    float p = 150;

    Eigen::Vector3f color = payload.color;
    Eigen::Vector3f point = payload.view_pos;
    Eigen::Vector3f normal = payload.normal;

    float kh = 0.2, kn = 0.1;

    float x = normal.x();
    float y = normal.y();
    float z = normal.z();
    Eigen::Vector3f t{ x * y / std::sqrt(x * x + z * z), std::sqrt(x * x + z * z), z * y / std::sqrt(x * x + z * z) };
    Eigen::Vector3f b = normal.cross(t);
    Eigen::Matrix3f TBN;
    TBN << t.x(), b.x(), normal.x(),
        t.y(), b.y(), normal.y(),
        t.z(), b.z(), normal.z();

    float u = payload.tex_coords.x(), v = payload.tex_coords.y();
    float w = payload.texture->width, h = payload.texture->height;

    float dU = kh * kn * (payload.texture->getColor(u + 1 / w, v).norm() - payload.texture->getColor(u, v).norm());
    float dV = kh * kn * (payload.texture->getColor(u, v + 1 / h).norm() - payload.texture->getColor(u, v).norm());

    Eigen::Vector3f ln{ -dU, -dV, 1 };
    //与凹凸贴图的区别就在于这句话
    point += (kn * normal * payload.texture->getColor(u, v).norm());
    normal = (TBN * ln).normalized();
    Eigen::Vector3f result_color = { 0, 0, 0 };

    for (auto& light : lights)
    {
        Eigen::Vector3f l = (light.position - point).normalized(), v = (eye_pos - point).normalized();// 光照方向和观察方向
        Eigen::Vector3f h = (l + v).normalized();// 半程向量
        Eigen::Vector3f I = light.intensity;// 光强
        float r2 = (light.position - point).dot(light.position - point);
        Eigen::Vector3f Ld = kd.cwiseProduct(I / r2) * std::max(0.0f, normal.dot(l));//cwiseProduct()函数允许Matrix直接进行点对点乘法,而不用转换至Array
        Eigen::Vector3f Ls = ks.cwiseProduct(I / r2) * std::pow(std::max(0.0f, normal.dot(h)), p);
        result_color += Ld + Ls;
    }

    return result_color * 255.f;
}
```

这里也存在我上面说的问题，即环境光的位置。
如果把环境光放在循环里面，渲染出来偏浅。
放在外面和说明基本一致，但还是有些偏暗。

displacement模型渲染结果：
![](/images/posts/1694861785612-7e79830e-273c-4740-aa25-f0dd869f0a63.png)
# 双线性插值
```cpp
Eigen::Vector3f getColorBilinear(float u, float v)
{
	// 限制(u, v)坐标范围
	u = std::fmin(1, std::fmax(u, 0));
	v = std::fmin(1, std::fmax(v, 0));

	auto u_img = u * width, v_img = (1 - v) * width;
	float u0 = std::fmax(1, floor(u_img - 0.5)), u1 = floor(u_img + 0.5);
	float v0 = std::fmax(1, floor(v_img - 0.5)), v1 = floor(v_img + 0.5);
	float s = (u_img - u0) / (u1 - u0), t = (v_img - v0) / (v1 - v0);
	auto c00 = image_data.at<cv::Vec3b>(v0, u0);
	auto c01 = image_data.at<cv::Vec3b>(v0, u1);
	auto c10 = image_data.at<cv::Vec3b>(v1, u0);
	auto c11 = image_data.at<cv::Vec3b>(v1, u1);
	auto c0 = c00 + s * (c01 - c00);
	auto c1 = c10 + s * (c11 - c10);
	auto color = c0 + t * (c1 - c0);
   // std::cout << color << std::endl;
	return Eigen::Vector3f(color[0], color[1], color[2]);
}
```

根据公式来算就行了。
![](/images/posts/1694861786045-6f9f2cec-8821-47ed-9a6d-b0490a5e2040.png)
这里放一个双线性插值后的效果对比，不过我不知道怎样缩小纹理图大小，我缩小后使用双线性插值牛牛鼻子旁边会出现鼻涕一样的颜色... 所以就用的原贴图来进行对比。
![](/images/posts/1694861786186-011ec089-e7ef-425b-9f63-ca60d86cd3eb.png)
鼻子边缘还是能看出效果的，不过效果不太明显就是了。
# 结果
![Normal&Phong.png](Normal&Phong.png)
![](/images/posts/1694861786410-c3bd24cc-f30e-4d01-8132-d54a9069eb95.png)
![](/images/posts/1694861786201-b4ed1302-e07c-4e89-9fb0-1679e9485efb.png)
# Reference

框架分析：

- [https://blog.csdn.net/Q_pril/article/details/123598746](/https://blog.csdn.net/Q_pril/article/details/123598746)

作业3论坛：

- [https://games-cn.org/forums/search/作业3/](/https://games-cn.org/forums/search/%E4%BD%9C%E4%B8%9A3/)

透视矫正：

- [https://zhuanlan.zhihu.com/p/144331875](/https://zhuanlan.zhihu.com/p/144331875)

作业框架问题：

- [https://games-cn.org/forums/topic/zuoye3-guanyushenduzhiwentizijicaidekengheyixiexiangfa/](/https://games-cn.org/forums/topic/zuoye3-guanyushenduzhiwentizijicaidekengheyixiexiangfa/)
- [https://zhuanlan.zhihu.com/p/509902950](/https://zhuanlan.zhihu.com/p/509902950)

插值与透视矫正：

- [https://blog.csdn.net/wangjiangrong/article/details/115326930?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-6-115326930.pc_agg_new_rank&utm_term=重心坐标对三角形内部插值&spm=1000.2123.3001.4430](/https://blog.csdn.net/wangjiangrong/article/details/115326930?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-6-115326930.pc_agg_new_rank&utm_term=%E9%87%8D%E5%BF%83%E5%9D%90%E6%A0%87%E5%AF%B9%E4%B8%89%E8%A7%92%E5%BD%A2%E5%86%85%E9%83%A8%E6%8F%92%E5%80%BC&spm=1000.2123.3001.4430)
