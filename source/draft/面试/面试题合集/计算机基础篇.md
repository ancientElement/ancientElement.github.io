---
title: 计算机基础篇
date: 2024-02-24
tags:
  - 面试题合集
---
## ⭐map的实现原理  
C#中使用Dictionary<TKey,TValue>，C++使用std::map<TK,TV>。
map的内部实现是[红黑树](http://wenwen.soso.com/z/Search.e?sp=S%E7%BA%A2%E9%BB%91%E6%A0%91&ch=w.search.yjjlink&cid=w.search.yjjlink)，Dictionary的实现是[哈希表](http://wenwen.soso.com/z/Search.e?sp=S%E5%93%88%E5%B8%8C%E8%A1%A8&ch=w.search.yjjlink&cid=w.search.yjjlink)。
#### 二叉排序树
要了解红黑树先了解**二叉排序树（二叉查找树）**
![](/images/posts/nc6qj.webp)
![](/images/posts/Pasted%20image%2020240207212901.png)

其实这就是二分的思想，与二分查找的思想一致。
但是，其增删查改的效率与树的形态有关。
增删查改**最好**时间复杂为`O(lg(n))`

![ag7vx](/images/posts/ag7vx.webp)

由于二叉树多次插入新节点的不平衡，带来查找效率大打折扣，于是使用一种方法使得二叉树搜索树能够**自平衡**。

#### 平衡二叉树和2-3树

于是有了**红黑树：** 

红黑树提出前有**平衡二叉树**和**2-3树**，这里大概讲一下：

- 平衡二叉树
平衡二叉树的规则很简单： 

1.保持是一个二叉树
2.每个节点的左子树和右子树的平衡因子的绝对值小于等于1，也就是左子树的高度减去右子树的高度的值为-1，0，1。

当插入一个节点时，如果某个节点的平衡因子被破坏，需要进行旋转操作，有LL，LR，RR，RL四种不平衡情况。只要遵循二叉树的原则来旋转，并且降低树的高度。

- 2-3树

这个暂且看这上面的内容：[红黑树比 AVL 树具体更高效在哪里？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/19856999/answer/2706230925)

#### 红黑树

1.节点是红色或黑色。

2.根节点是黑色。

3.每个叶子节点都是黑色的空节点（NIL节点）。

4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)

5.从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

其实看起来规则多多，只要对照平衡二叉树其实规则一致。都是为了保持平衡，也就是保持平衡因子。

红黑树相比与平衡二叉树可能某些时候出现不平衡的现象，因为有时候红黑树只需要通过染色，就可以达到目的。

具体看[红黑树比 AVL 树具体更高效在哪里？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/19856999/answer/2706230925)

## 哈希表

先看[24散列表(哈希表)的查找](计算机科学基础/数据结构与算法基础/24散列表(哈希表)的查找.md)这个复习一下

可以这样理解，哈希表就是将其**关键数据**（key）转换成储存其的地址，通过`hash`函数从**关键数据**（key）得到地址从而直接访问数据。

### 构造方法
#### 直接定址发和除留余数法

用于简单的数据，但是有时候会有冲突。

例如处理10，20，30，40，50

直接取其十位，或者用一个取模函数得到他们余数不相等的模

处理冲突的方法  

#### 线性探测法

如果有冲突就找下一个位置

![77tvf](/images/posts/77tvf.webp)
![ipa3l](/images/posts/ipa3l.webp)

#### 二次探测

![x5v3y](/images/posts/x5v3y.webp)

![qzlya](/images/posts/qzlya.webp)

#### 伪随机探测

![avwla](/images/posts/avwla.webp)

#### 链地址法

![a6mii](/images/posts/a6mii.webp)
![l1fl3](/images/posts/l1fl3.webp)

### C# Dictionary<TKey,TValue>

[【C#】浅析C# Dictionary实现原理 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/96633352)

其实Dictionary就是使用链地址法的哈希表。其容量是大于当前容量的最小质数。当其容量不足的时候会进行扩容。

## DFS和BFS
### 先复习一下图这个结构

图,一般用于表示多对多的数据结构

#### 数组表示法: 临界矩阵

用一个**顶点表**表示顶点数据,再用一个二维数组**临接矩阵**表示顶点的连接关系。

![](/images/posts/Pasted%20image%2020231012195424.png)

在有向图中只行表示**出度**

**有权网**，并且图中的顶点可以带有权值。

![](/images/posts/Pasted%20image%2020231012195700.png)

#### 临界表： 链表表示法

![](/images/posts/709d87afc7f8777f8b93b828c7bf986bd6145073.png@1256w_594h_!web-article-pic.webp)

### 图的遍历

遍历的实质就是找到**邻接点**

[19图的遍历](计算机科学基础/数据结构与算法基础/19图的遍历.md)

#### 深度优先

**一条道走到黑**直到所有的邻接点都被访问过了。再退回到上一步。直到所有的顶点都被访问过。

有点像**先序遍历**

![](/images/posts/1a13f091ca7e71fbbb96a6d79350c36e2fbe85ea.png@1256w_664h_!web-article-pic.webp)![](/images/posts/18e214a6a035d9d4802cd2b24f47f26ec517eca5.png@1256w_622h_!web-article-pic.webp)
![](/images/posts/cd8db24e1a36ec22ceb9834e132c41b8a3f11b23.png@1256w_582h_!web-article-pic.webp)

```c++
//伪代码
struct Graph{
	int vetex[];
	int relat_table[][];
	int count;
}

bool visited[];
void DFS(Graph graph,int index){
	visited = new int[graph.count];
	visited[index] = true;
	cout << graph[index];
	for(int i;i < graph.count;i++) {
		if(graph.relat_table[index][i] && !visited[i]) {
			 DFS(graph,i);
		}
	} 
}
```
#### 广度优先

简而言之就是一个**先进先出**的队列

**广度优先搜索算法**（英语：Breadth-First Search，缩写BFS），又译作宽度优先搜索，或横向优先搜索，是一种图形搜索方法。简单的说，BFS是从根节点开始，沿着树德宽度遍历树德节点。如果所有节点均被访问，则算法终止。广度优先搜索的实现一般采用open-closed表。

BFS是一种盲目搜索法，目的是系统的展开并检查图中的所有节点，以寻找结果。换句话说，它并不考虑结果的可能地址，彻底的搜索整张图，直到找到结果为止。

从算法的观点，所有因为展开节点而得到的子节点都会被加入一个先进先出的队列中。一般在实现过程中，其邻居节点尚未被检验过的节点会被放置在一个被称为open的容器中（例如队列或者链表），而被检验过的节点则被放置在被称为closed的容器中。（open-closed表)

![0dzs6](/images/posts/0dzs6.webp)

### 广度优先搜索（BFS），实现的方法：

1. 首先将根节点放入队列中；

2. 从队列中取出第一个节点，并检验它是否为目标：

·如果找到目标，结束搜索并回传结果；

·否则将它所有尚未检验过的直接子节点加入队列中。

3. 若队列为空，表示整张图都检查过了--也就代表图中没有要搜索的目标。结束搜索并回传“找不到目标”；

4. 重复步骤2。


## ⭐内存五大区  

1. **栈区（stack）**:存放函数形参和局部变量（auto类型），由编译器自动分配和释放。
2. **堆区（heap）**:该区由程序员申请后使用，需要手动释放否则会造成内存泄漏。如果程序员没有手动释放，那么程序结束时可能由OS回收。
3. **全局/静态存储区**：存放全局变量和静态变量（包括静态全局变量与静态局部变量），初始化的全局变量和静态局部变量放在一块，未初始化的放在另一块。
4. **文字常量区**：常量在统一运行被创建，常量区的内存是只读的，程序结束后由系统释放。
5. **程序代码区**：存放程序的二进制代码，内存由系统管理

## ⭐栈和堆区别  

摘自[堆和栈的区别 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/78478567)

```c
//main.cpp    
  int   a   =   0;   全局初始化区    
  char   *p1;   全局未初始化区    
  main()    
  {    
  int   b;   栈    
  char   s[]   =   "abc";   栈    
  char   *p2;   栈    
  char   *p3   =   "123456";   123456/0在常量区，p3在栈上。    
  static   int   c   =0；   全局（静态）初始化区    
  p1   =   (char   *)malloc(10);    
  p2   =   (char   *)malloc(20);    
  分配得来得10和20字节的区域就在堆区。    
  strcpy(p1,   "123456");   123456/0放在常量区，编译器可能会将它与p3所指向的"123456"  
  优化成一个地方。    
  }    
```

### 申请方式  

- **stack**:  
由系统自动分配。 例如，声明在函数中一个局部变量 int b; 系统自动在栈中为b开辟空  
间  

- **heap**:  
需要程序员自己申请，并指明大小，在c中malloc函数  
如`p1 = (char *)malloc(10);`  

在C++中用new运算符  
如`p2 = new char[10];`  

但是注意p1、p2本身是在栈中的。

### 申请后系统的响应  

**栈**：只要栈的**剩余空间**大于所申请空间，系统将为程序提供内存，否则将报异常提示**栈溢出**。

**堆**：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，  
会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表  
中删除，并将该结点的空间分配给程序。

另外，对于大多数系统，会在这块内存空间中的**首地址**处记录本次**分配的大小**，这样，代码中的`delete`语句才能正确的**释放**本内存空间。  
另外，由于找到的堆结点的大小不一定正好等于**申请的大小**，系统会自动的将多余的那部  
分重新放入空闲链表中。

## UDP和TCP区别

**TCP/IP协议**是一个**协议簇**。里面包括很多协议的，UDP只是其中的一个， 之所以命名为TCP/IP协议，因为TCP、IP协议是两个很重要的协议，就用他两命名了。

TCP/IP协议集包括**应用层**,**传输层**，**网络层**，**网络访问层**。

### 其中应用层包括:

1、超文本传输协议（**HTTP**）:万维网的基本协议；  
2、文件传输（**TFTP**简单文件传输协议）；  
3、远程登录（**Telnet**），提供远程访问其它主机功能, 它允许用户登录internet主机，并在这台主机上执行命令；  
4、网络管理（**SNMP**简单网络管理协议），该协议提供了监控网络设备的方法， 以及配置管理,统计信息收集,性能管理及安全管理等；  
5、域名系统（**DNS**），该系统用于在internet中将域名及其公共广播的网络节点转换成IP地址。

### 其次网络层包括:

1、Internet协议（**IP**）；  
2、Internet控制信息协议（**ICMP**）；  
3、地址解析协议（**ARP**）；  
4、反向地址解析协议（**RARP**）。

### 最后说网络访问层:

网络访问层又称作主机到网络层（host-to-network），网络访问层的功能包括**IP地址**与**物理地址**硬件的映射， 以及将IP封装成帧。基于不同硬件类型的网络接口，网络访问层定义了和物理介质的连接。当然我这里说得不够完善，TCP/IP协议本来就是一门学问，每一个分支都是一个很复杂的流程， 但我相信每位学习软件开发的同学都有必要去仔细了解一番。
### 下面着重讲解一下TCP协议和UDP协议的区别

TCP（Transmission Control Protocol，传输控制协议）是**面向连接**的协议，也就是说，在收发数据前，必须和对方**建立可靠的连接**。 一个TCP连接必须要经过**三次对话**才能建立起来，其中的过程非常复杂， 只简单的描述下这三次对话的简单过程：

1）主机**A向主机B**发出连接请求数据包：“我想给你发数据，可以吗？”，这是第一次对话；

2）主机**B向主机A**发送同意连接和要求同步 （同步就是两台主机一个在发送，一个在接收，协调工作）的数据包 ：“可以，你什么时候发？”，这是第二次对话；

3）主机**A再发出**一个数据包确认主机B的要求同步：“我现在就发，你接着吧！”， 这是第三次对话。

三次“对话”的目的是使数据包的发送和接收同步， 经过三次“对话”之后，主机A才向主机B正式发送数据。

### TCP三次握手过程

第一次握手：**主机A通过向主机B**发送一个含有**同步序列号**的标志位的数据段给主机B，向主机B 请求建立连接，通过这个数据段， 主机A告诉主机B 两件事：我想要和你通信；你可以用哪个序列号作为**起始数据段**来回应我。

>有点帧同步的味道了

第二次握手：**主机B 收到主机A**的请求后，用一个带有 **确认应答（ACK）** 和 **同步序列号（SYN）** 标志位的数据段响应主机A，也告诉主机A两件事：我已经收到你的请求了，你可以传输数据了；你要用那个序列号作为起始数据段来回应我

第三次握手：主机A收到这个数据段后，再**发送一个确认应答**，确认已收到主机B 的数据段："我已收到回复，我现在要开始传输实际数据了，这样3次握手就完成了，主机A和主机B 就可以传输数据了。

#### 3次握手的特点

**没有应用层的数据** ,SYN这个标志位只有在TCP建立连接时才会被置1 ,握手完成后SYN标志位被置0。

### 断开连接要进行4次

第一次： 当主机**A完成数据传输后**,将控制位FIN置1，提出停止TCP连接的请求 ；

第二次： 主机**B收到FIN后对其作出响应**，确认这一方向上的TCP连接将关闭,将ACK置1；

第三次： 由**B端再提出反方向的关闭请求**,将FIN置1；

第四次： 主机**A对主机B的请求进行确认**，将ACK置1，双方向的关闭结束。

由TCP的**三次握手和四次断开**可以看出，TCP使用面向连接的通信方式， 大大提高了数据通信的可靠性，使发送数据端和接收端在数据正式传输前就有了交互， 为数据正式传输打下了可靠的基础。

### **UDP（User Data Protocol，用户数据报协议）**

1、UDP是一个**非连接的协议**，传输数据之前源端和终端不建立连接， 当它想传送时就简单地去抓取来自应用程序的数据，并尽可能快地把它扔到网络上。 在发送端，UDP传送数据的速度仅仅是**受应用程序生成数据**的速度、 计算机的能力和**传输带宽**的限制； 在接收端，UDP把每个消息段放在队列中，应用程序每次从队列中读一个消息段。

2、 由于传输数据不建立连接，因此也就不需要维护连接状态，包括收发状态等， 因此一台服务机**可同时向多个客户机传输相同的消息**。

3、UDP**信息包的标题很短**，只有8个字节，相对于TCP的20个字节信息包的额外开销很小。

4、吞吐量不受拥挤控制算法的调节，只受应用软件生成数据的速率、传输带宽、 源端和终端主机性能的限制。

5、UDP使用尽最大努力交付，即**不保证可靠交付**， 因此主机不需要维持复杂的链接状态表（这里面有许多参数）。

6、UDP是面向报文的。发送方的UDP对应用程序交下来的报文， 在添加首部后就向下交付给IP层。既不拆分，也不合并，而是保留这些报文的边界， 因此，应用程序需要选择合适的报文大小。

用“ping”命令来测试两台主机之间TCP/IP通信是否正常， 其实“ping”命令的原理就是向对方主机发送UDP数据包，然后对方主机确认收到数据包， 如果数据包是否到达的消息及时反馈回来，那么网络就是通的。

**ping命令**是用来探测主机到主机之间是否可通信，如果不能**ping**到某台主机，表明不能和这台主机建立连接。**ping命令**是使用 IP 和网络控制信息协议 (ICMP)，因而没有涉及到任何传输协议(UDP/TCP) 和应用程序。它发送icmp回送请求消息给目的主机。

ICMP协议规定：目的主机必须返回ICMP回送应答消息给源主机。如果源主机在一定时间内收到应答，则认为主机可达。

### **小结TCP与UDP的区别：**

1、基于**连接与无连接**；

2、对**系统资源**的要求（TCP较多，UDP少）；

3、UDP程序结构较简单；

4、流模式与数据报模式 ；

5、TCP保证数据**正确性**，UDP可能丢包；

6、TCP保证**数据顺序**，UDP不保证。

## 线程和进程的区别 

[线程和进程的区别 • Worktile社区](https://worktile.com/kb/p/36374)
[一文读懂什么是进程、线程、协程 - 回首笑人间 - 博客园 (cnblogs.com)](https://www.cnblogs.com/Survivalist/p/11527949.html#%E8%BF%9B%E7%A8%8B)
### 什么是进程？

进程（Process）是计算机中的程序关于**某数据集合**上的一次**运行活动**，是系统进行**资源分配**和**调度**的**基本单位**，是操作系统结构的基础。在早期面向进程设计的计算机结构中，进程是程序的基本执行实体；在当代面向线程设计的计算机结构中，**进程是线程的容器**。程序是指令、数据及其组织形式的描述，**进程是程序的实体**。

进程是60年代初首先由麻省理工学院的MULTICS系统和IBM公司的CTSS/360系统引入的。

进程是一个具有**独立功能的程序**关于某个数据集合的一次**运行活动**。它可以**申请和拥有系统资源**，是一个动态的概念，是一个活动的实体。**它不只是程序的代码**，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。

进程的概念主要有两点：名列前茅，进程是一个实体。每一个进程都有它自己的地址空间，一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。文本区域存储处理器执行的代码；数据区域存储变量和进程执行期间使用的动态分配的内存；堆栈区域存储着活动过程调用的指令和本地变量。第二，进程是一个“执行中的程序”。程序是一个没有生命的实体，只有**处理器赋予程序生命时（操作系统执行之）**，它才能成为一个活动的实体，我们称其为进程。

### 线程

在早期的操作系统中并没有线程的概念，进程是能拥有资源和独立运行的最小单位，也是程序执行的最小单位。任务调度采用的是时间片轮转的抢占式调度方式，而进程是任务调度的最小单位，每个进程有各自独立的一块内存，使得各个进程之间内存地址相互隔离。

后来，随着计算机的发展，对CPU的要求越来越高，**进程之间的切换开销较大**，已经无法满足越来越复杂的程序的要求了。于是就发明了线程。

线程是**程序执行**中一个**单一的顺序控制流程**，是**程序执行流**的**最小单元**，是处理器调度和分派的基本单位。一个进程可以有一个或**多个线程**，各个线程之间共享程序的内存空间(也就是所在进程的内存空间)。一个标准的线程由**线程ID**、当前**指令指针(PC)**、**寄存器**和**堆栈**组成。而进程由内存空间(代码、数据、进程空间、打开的文件)和一个或多个线程组成。  

（读到这里可能有的读者迷糊，感觉这和Java的内存空间模型不太一样，但如果你深入的读过深入理解Java虚拟机这本书的话你就会恍然大悟）
### 1、根本区别

进程是操作系统进行资源分配的最小单元，线程是操作系统进行运算调度的最小单元。进程（Process）是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。

### 2、从属关系不同

进程中包含了线程，线程属于进程。一个进程可以有很多线程，每条线程并行执行不同的任务。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。

### 3、开销不同

进程的创建、销毁和切换的开销都远大于线程。由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效的提高系统内多个程序间并发执行的程度，从而显著提高系统资源的利用率和吞吐量。

### 4、拥有资源不同

每个进程有自己的内存和资源，一个进程中的线程会共享这些内存和资源。进程是资源分配的基本单位。所有与该进程有关的资源，都被记录在进程控制块PCB中。以表示该进程拥有这些资源或正在使用它们。另外，进程也是抢占处理机的调度单位，它拥有一个完整的虚拟地址空间。当进程发生调度时，不同的进程拥有不同的虚拟地址空间，而同一进程内的不同线程共享同一地址空间。

### 5、控制和影响能力不同

子进程无法影响父进程，而子线程可以影响父线程，如果主线程发生异常会影响其所在进程和子线程。与进程相对应，线程与资源分配无关，它属于某一个进程，并与进程内的其他线程一起共享进程的资源。

### 6、CPU利用率不同

进程的CPU利用率较低，因为上下文切换开销较大，而线程的CPU的利用率较高，上下文的切换速度快。在多核或多CPU，或支持Hyper-threading的CPU上使用多线程程序设计的好处是显而易见，即提高了程序的执行吞吐率。在单CPU单核的计算机上，使用多线程技术，也可以把进程中负责I/O处理、人机交互而常被阻塞的部分与密集计算的部分分开来执行，编写专门的workhorse线程执行密集计算，从而提高了程序的执行效率。

## 进程间、线程间的通讯方式

[进程间通信和线程间通信的几种方式 - 反光的小鱼儿 - 博客园 (cnblogs.com)](https://www.cnblogs.com/fanguangdexiaoyuer/p/10834737.html#_label3)
### 进程通信

#### 管道(pipe)

管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。

#### 有名管道 (namedpipe)

有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。

#### 信号量(semaphore)

信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。

#### 消息队列(messagequeue)

消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。

#### 信号 (sinal)

信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

#### 共享内存(shared memory)

共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。

#### 套接字(socket)

套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。、

### 线程间的通信方式

#### 锁机制：包括互斥锁、条件变量、读写锁

互斥锁提供了以排他方式防止数据结构被并发修改的方法。   
读写锁允许多个线程同时读共享数据，而对写操作是互斥的。   
条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

wait/notify 等待

Volatile 内存共享

CountDownLatch 并发工具

CyclicBarrier 并发工具

#### 信号量机制(Semaphore)

包括无名线程信号量和命名线程信号量。

#### 信号机制(Signal)

类似进程间的信号处理。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

## 什么是协程

[什么是协程？ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/172471249)
### 为什么需要协程？

>哈哈
>**线程**因**进程**切换而生
>**协程**因**进程**开销而生

我们都知道多线程，当需要同时执行多项任务的时候，就会采用多线程并发执行。拿手机支付举例子，当收到付款信息的时候，需要查询数据库来判断余额是否充足，然后再进行付款。

假设最开始我们只有可怜的10个用户，收到10条付款消息之后，我们开启启动10个线程去查询数据库，由于用户量很少，结果马上就返回了。第2天用户增加到了100人，你选择增加100个线程去查询数据库，等到第三天，你们加大了优惠力度，这时候有1000人同时在线付款，你按照之前的方法，继续采用1000个线程去查询数据库，并且隐隐觉察到有什么不对。

![0q383](/images/posts/0q383.webp)

不断增长的线程

几天之后，见势头大好，运营部门开始不停的补贴消费券，展开了史无前例的大促销，你们的用户开始爆炸增长，这时候有10000人同时在线付款，你打算启动10000个线程来处理任务。等等，问题来了，因为每个线程至少会占用4M的内存空间，10000个线程会消耗39G的内存，而服务器的内存配置只有区区8G，这时候你有2种选择，一是选择增加服务器，二是选择提高代码效率。那么是否有方法能够提高效率呢？

我们知道操作系统在**线程等待IO**的时候，会**阻塞当前线程**，切换到其它线程，这样在当前线程等待IO的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题。**一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间。**


![](media/v2-edafcd23346b92693d70da0032486914_720w.webp)

线程切换

协程刚好可以解决上述2个问题。协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。协程并没有增加线程数量，只是在线程的基础之上通过**分时复用**的方式运行多个协程，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。

![](media/v2-f4fb2dea86d909ed60498b7021d0fe66_720w.webp)

协程切换

回到上面的问题，我们只需要启动100个线程，每个线程上运行100个协程，这样不仅减少了线程切换开销，而且还能够同时处理10000个读取数据库的任务，很好的解决了上述任务。

知道了协程的工作方式，那么我们再看下使用协程有哪些注意事项。

### **协程的注意事项**

实际上协程并不是什么银弹，协程只有在等待IO的过程中才能重复利用线程，上面我们已经讲过了，线程在等待IO的过程中会陷入阻塞状态，意识到问题没有？

假设协程运行在线程之上，并且**协程调用了一个阻塞IO操作**，这时候会发生什么？实际上操作系统并不知道协程的存在，它只知道线程，因此在协程调用阻塞IO操作的时候，操作系统会**让线程进入阻塞状态**，当前的协程和其它绑定在该线程之上的**协程**都会**陷入阻塞**而得不到调度，这往往是不能接受的。

因此**在协程中不能调用导致线程阻塞的操作**。也就是说，协程只有和**异步IO**结合起来，才能发挥最大的威力。

那么如何处理在协程中调用阻塞IO的操作呢？一般有2种处理方式：

1. **在调用阻塞IO操作的时候，重新启动一个线程去执行这个操作，等执行完成后，协程再去读取结果。这其实和多线程没有太大区别。**
2. **对系统的IO进行封装，改成异步调用的方式，这需要大量的工作，最好寄希望于编程语言原生支持。**

协程对计算密集型的任务也没有太大的好处，计算密集型的任务本身不需要大量的线程切换，因此协程的作用也十分有限，反而还增加了协程切换的开销。

以上就是协程的注意事项。这里顺带一提JavaScript的异步变同步的调用方式，如果协程能够实现该类型的语法，不仅可以把异步操作变为同步，同时在IO操作的时候还能够不占用CPU，写起来非常方便。

**异步变同步的调用方式只是一种编程方式，不管是用线程还是用协程都可以实现这种编程方式，好处是不用在处理非常多的回调。**

```js
async function getProcessedData(url) {
  let v;
  try {
    v = await downloadData(url);
  } catch(e) {
    v = await downloadFallbackData(url);
  }
  try {
    return await processDataInWorker(v);
  } catch (e) {
    return null;
  }
}
```

## **总结**

在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是**降低了系统内存**，二是减少了**系统切换开销**，因此系统的性能也会提升。

在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。

**协程只有和异步IO结合起来才能发挥出最大的威力。**

## 栈内存增长顺序  


## windows linux 系统的大小端